{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Binary Classification Example\n",
    "\n",
    "From the book [\"Deep Learning with Python\"](https://www.manning.com/books/deep-learning-with-python) by Francois Chollet\n",
    "\n",
    "Two-class classification or binary classification is some of the most common types of machine learning problems an analysts will encounter in the real world. I have used this method in sales operations to look at what sales opportunities are likley to close to seeing when a customer is likely to leave in what is know as churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The IMDb Data-Set\n",
    "\n",
    "The Internet Movie Database is an online database that houses information about movies, televsion shows and video games. This dataset has a set of 50K highly polarized reviews. The reviews are spilt into 25K reviews for training and 25K for testing. Each set contains a review mix of 50% positive and 50% negative.\n",
    "\n",
    "This data has already been preprocessed. The reviews have been turned into sequences of integers. Each integer repersents a word in a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "\n",
    "This data comes prepackaged with Keras. You can load the code with the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the `num_words = 10000` takes the top 10K words by frequency in the training data, basically meaning the rare words will be removed. This means that our data will more of a managable size to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take A Quick Look\n",
    "\n",
    "`train_data` and `test_data` are lists of reviews. So each review is a list of word indices with an encoding of a sequence of words. The labels `train_labels` and `test_labels` are lists of 0s and 1s where 0 stands for *negative* review and 1 is a *positive* review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 47,\n",
       " 8,\n",
       " 30,\n",
       " 31,\n",
       " 7,\n",
       " 4,\n",
       " 249,\n",
       " 108,\n",
       " 7,\n",
       " 4,\n",
       " 5974,\n",
       " 54,\n",
       " 61,\n",
       " 369,\n",
       " 13,\n",
       " 71,\n",
       " 149,\n",
       " 14,\n",
       " 22,\n",
       " 112,\n",
       " 4,\n",
       " 2401,\n",
       " 311,\n",
       " 12,\n",
       " 16,\n",
       " 3711,\n",
       " 33,\n",
       " 75,\n",
       " 43,\n",
       " 1829,\n",
       " 296,\n",
       " 4,\n",
       " 86,\n",
       " 320,\n",
       " 35,\n",
       " 534,\n",
       " 19,\n",
       " 263,\n",
       " 4821,\n",
       " 1301,\n",
       " 4,\n",
       " 1873,\n",
       " 33,\n",
       " 89,\n",
       " 78,\n",
       " 12,\n",
       " 66,\n",
       " 16,\n",
       " 4,\n",
       " 360,\n",
       " 7,\n",
       " 4,\n",
       " 58,\n",
       " 316,\n",
       " 334,\n",
       " 11,\n",
       " 4,\n",
       " 1716,\n",
       " 43,\n",
       " 645,\n",
       " 662,\n",
       " 8,\n",
       " 257,\n",
       " 85,\n",
       " 1200,\n",
       " 42,\n",
       " 1228,\n",
       " 2578,\n",
       " 83,\n",
       " 68,\n",
       " 3912,\n",
       " 15,\n",
       " 36,\n",
       " 165,\n",
       " 1539,\n",
       " 278,\n",
       " 36,\n",
       " 69,\n",
       " 2,\n",
       " 780,\n",
       " 8,\n",
       " 106,\n",
       " 14,\n",
       " 6905,\n",
       " 1338,\n",
       " 18,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 610,\n",
       " 40,\n",
       " 6,\n",
       " 87,\n",
       " 326,\n",
       " 23,\n",
       " 2300,\n",
       " 21,\n",
       " 23,\n",
       " 22,\n",
       " 12,\n",
       " 272,\n",
       " 40,\n",
       " 57,\n",
       " 31,\n",
       " 11,\n",
       " 4,\n",
       " 22,\n",
       " 47,\n",
       " 6,\n",
       " 2307,\n",
       " 51,\n",
       " 9,\n",
       " 170,\n",
       " 23,\n",
       " 595,\n",
       " 116,\n",
       " 595,\n",
       " 1352,\n",
       " 13,\n",
       " 191,\n",
       " 79,\n",
       " 638,\n",
       " 89,\n",
       " 2,\n",
       " 14,\n",
       " 9,\n",
       " 8,\n",
       " 106,\n",
       " 607,\n",
       " 624,\n",
       " 35,\n",
       " 534,\n",
       " 6,\n",
       " 227,\n",
       " 7,\n",
       " 129,\n",
       " 113]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should not have a word value that goes over 10K in our `train_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are these numbers in english? Below is a decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index() #word_index is a dictionary mapping\n",
    "reverse_word_index = dict(\n",
    "[(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "reverse_word_index.get(i - 3, '?') for i in train_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had ? working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how ? this is to watch save yourself an hour a bit of your life\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
